
# ğŸ´ Lenormand LLM Reader (FastAPI + Next.js)

*A bilingual Lenormand reading service prototype powered by an LLM.*


<p align="center">
  <em>âš ï¸ The preview image above is a temporary placeholder. It may use artwork with unclear copyright status and is NOT intended for redistribution. Will be replaced with original assets later.</em>
</p>

---

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10%2B-3776AB?style=for-the-badge&logo=python" />
  <img src="https://img.shields.io/badge/FastAPI-Backend-009688?style=for-the-badge&logo=fastapi" />
  <img src="https://img.shields.io/badge/Next.js-Frontend-000000?style=for-the-badge&logo=next.js" />
  <img src="https://img.shields.io/badge/TypeScript-4.x-3178C6?style=for-the-badge&logo=typescript" />
  <img src="https://img.shields.io/badge/LLM-OpenAI_mock-412991?style=for-the-badge&logo=openai" />
</p>

---

## âœ¨ Overview

**Lenormand LLM Reader** is a prototype stack for a **bilingual Lenormand reading service**:

- **FastAPI** backend  
  - Handles spread logic, shuffling, basic request/response models  
  - Provides stubs for LLM + translation services  
- **Next.js** frontend  
  - Minimal UI to send a question, choose a spread, and render results  

The goal is to model the **end-to-end flow** of:

> â€œKorean question â†’ spread selection â†’ card sampling â†’ LLM reading (EN) â†’ translated reading (KO)â€

â€¦while keeping all LLM / translation bits swappable.

---

## ğŸ“‚ Project Structure

í˜„ì¬ ë¦¬í¬ í´ë” ê¸°ì¤€ìœ¼ë¡œ ì‹¤ì œ êµ¬ì¡°ë¥¼ ë°˜ì˜í•œ í”„ë¡œì íŠ¸ ê°œìš”:

```text
lenormand-llm-reader/
â”‚
â”œâ”€â”€ main.py               # FastAPI app bootstrap & router include
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ reading.py        # /api/reading endpoint, Pydantic models, wiring
â”‚
â”œâ”€â”€ services/             # Pluggable service layer
â”‚   â”œâ”€â”€ llm_client.py         # Prompt builder + mock LLM response
â”‚   â”œâ”€â”€ translation_client.py # Mock translator (ko <-> en)
â”‚   â””â”€â”€ spread_engine.py      # Loads spreads/cards, shuffles, assigns positions
â”‚
â”œâ”€â”€ data/                 # JSON templates (deck & spreads)
â”‚   â”œâ”€â”€ cards.json            # Keys 1..36 prepared for Lenormand metadata
â”‚   â””â”€â”€ spreads.json          # Pastâ€“Presentâ€“Future, SOA, 3x3 box, Grand Tableau
â”‚   # (ignored) lenormand_notes.txt - personal notes, excluded via .gitignore
â”‚
â”œâ”€â”€ pages/                # Next.js pages
â”‚   â”œâ”€â”€ index.tsx             # Landing / entry page
â”‚   â””â”€â”€ reading.tsx           # Reading request + result rendering
â”‚
â”œâ”€â”€ components/           # Frontend building blocks
â”‚   â”œâ”€â”€ SpreadSelector.tsx    # Choose spread type
â”‚   â”œâ”€â”€ CardView.tsx          # Individual card view
â”‚   â””â”€â”€ ResultView.tsx        # LLM reading display
â”‚
â”œâ”€â”€ static/               # Static assets (preview images, etc.)
â”‚   â””â”€â”€ cards/                # Card artwork (ignored by git)
â”‚
â”œâ”€â”€ templates/            # (Optional) HTML templates for manual testing
â”‚
â”œâ”€â”€ test_spread.py        # Quick Python-side sanity tests for spread_engine
â”‚
â”œâ”€â”€ .gitignore            # venv/.env, static/cards, data/lenormand_notes, tools/â€¦
â””â”€â”€ README.md
````

> ğŸ”’ **Privacy / Safety Note (.gitignore)**
>
> * `static/cards/*` â†’ card images that might have copyright issues
> * `data/lenormand_notes.txt` â†’ personal reading notes
> * `tools/` â†’ local helpers, experiments
> * `.env`, `.env*`, `venv/` â†’ secrets & local environment
>
> ì´ ë¦¬í¬ëŠ” ì‹¤ì œ ë°°í¬ìš©ì´ ì•„ë‹ˆë¼, **êµ¬ì¡°/íë¦„ì„ ë³´ì—¬ì£¼ëŠ” í”„ë¡œí† íƒ€ì…**ì…ë‹ˆë‹¤.

---

## ğŸ§  Backend: FastAPI

### 1. Create a virtual environment

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### 2. Install backend dependencies

(ìµœì†Œ ì˜ˆì‹œ. ì‹¤ì œë¡œëŠ” `requirements.txt`ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥)

```bash
pip install fastapi uvicorn
# plus: pydantic, httpx, etc. depending on your implementation
```

### 3. Run the server

```bash
uvicorn main:app --reload
```

* Health check: `GET http://localhost:8000/health`
* Reading API: `POST http://localhost:8000/api/reading`

### Example Request

```json
{
  "question_ko": "ì˜¬í•´ ì»¤ë¦¬ì–´ ë°©í–¥ì€?",
  "category": "career",
  "spread_type": "past_present_future"
}
```

### Example Response Shape

```json
{
  "reading_en": {
    "summary_en": "...",
    "overall_story_en": "...",
    "action_items_en": []
  },
  "reading_ko": {
    "summary_ko": "...",
    "overall_story_ko": "...",
    "action_items_ko": []
  },
  "cards": [
    {
      "card_id": 1,
      "position_label_en": "Past",
      "row": 1,
      "column": 1
    }
  ],
  "spread_type": "past_present_future"
}
```

> ğŸ‘‰ In this prototype, `LLMClient` and `TranslationClient` return mocked responses.
> For a real deployment, plug in actual providers (OpenAI, NLLB, etc.) and secrets via `.env`.

---

## ğŸ–¼ Frontend: Next.js

```bash
npm install
npm run dev
```

By default, the frontend expects the API at:

```text
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
```

* `/reading` page posts to `POST /api/reading`
* Renders:

  * Selected spread
  * Card positions
  * `reading_en` / `reading_ko` blocks

---

## ğŸ“¦ Data Templates

* `data/cards.json`

  * keys `1..36`
  * structure ready for:

    * names (EN/KR)
    * domain-specific keywords
    * interpretive text

* `data/spreads.json`

  * definitions for:

    * Pastâ€“Presentâ€“Future
    * Situationâ€“Obstacleâ€“Advice
    * 3Ã—3 Box
    * Grand Tableau (8Ã—4+4)

ì´ JSON ì„¤ê³„ëŠ” ë‚˜ì¤‘ì— **LLM í”„ë¡¬í”„íŠ¸ìš© RAG ì»¨í…ìŠ¤íŠ¸**ë¡œ í™•ì¥í•˜ê¸° ì‰½ê²Œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ§ª Manual Test (Backend-only)

1. Start backend:

```bash
uvicorn main:app --reload
```

2. POST to:

```text
http://localhost:8000/api/reading
```

with:

```json
{
  "question_ko": "ì§€ê¸ˆ ì·¨ì—… ì¤€ë¹„ ë°©í–¥ì´ ë§ëŠ”ì§€ ì•Œê³  ì‹¶ì–´ìš”",
  "category": "career",
  "spread_type": "past_present_future"
}
```

3. Expect:

* HTTP 200
* `reading_en.summary_en` populated in English (mock)
* `reading_ko.summary_ko` populated in Korean (mock)
* `cards` + `spread_type` echoed back according to `spread_engine` logic

---

## ğŸ–¼ Image Assets & Copyright

> âš ï¸ **Important notice**

* Some images under `static/` (especially card-like artwork) are **temporary placeholders**.
* ì›ë³¸ ì¶œì²˜ì˜ ì €ì‘ê¶Œ ìƒíƒœê°€ ëª…í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë©°,
  **ìƒì—…ì /ê³µê°œ ë°°í¬ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.**
* ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ”:

  * ì§ì ‘ ì œì‘í•œ ì¼ëŸ¬ìŠ¤íŠ¸
  * ìƒì—…ì  ì‚¬ìš©ì´ í—ˆìš©ëœ ì—ì…‹
  * ë˜ëŠ” ì™„ì „íˆ í…ìŠ¤íŠ¸ ê¸°ë°˜ UI
    ì¤‘ í•˜ë‚˜ë¡œ êµì²´í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ”® Roadmap / Ideas

* Integrate real LLM + translation APIs
* Fill `cards.json` with full Lenormand metadata (EN/KR)
* Add persistent reading history
* Add user profiles & rate limiting
* Replace placeholder art with original, copyright-safe illustrations

---

## ğŸ‘¤ About

Built as a personal exploration into:

* LLM-backed **symbolic systems** (Lenormand)
* **Backendâ€“Frontend** separation with FastAPI & Next.js
* Designing JSON schemas for card-based RAG-style prompts

Author: **ë”°ì˜´í‘œ**
LLM collaborator: **Rico**
